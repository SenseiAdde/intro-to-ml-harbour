{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5Fj-ahf25os"
   },
   "source": [
    "## Assignment 02. Logistic regression and kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qZX1Urv425ov"
   },
   "source": [
    "### Part 1. Small numpy workout (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ABwrGwvF25ow"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GYgIRlqf25o0"
   },
   "outputs": [],
   "source": [
    "# Create a matrix named A with shape (10, 10) from ordered natural numbers from 0 to 100 (excluded)\n",
    "# hint: np.arange(100).reshape((10, 10))\n",
    "\n",
    "A = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7aB62Lzk25o2"
   },
   "outputs": [],
   "source": [
    "# Compute mean values of the matrix row-wise\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MTLnNqV425o5"
   },
   "outputs": [],
   "source": [
    "# Transpose matrix A\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WgDUhrYV25o8"
   },
   "outputs": [],
   "source": [
    "# Multiply matrix A and transposed A element-wise\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xwgLyFDD25o9"
   },
   "outputs": [],
   "source": [
    "# Compute matrix product of matrix A and itself and save the result into matrix B\n",
    "# https://en.wikipedia.org/wiki/Matrix_multiplication\n",
    "# or https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\n",
    "\n",
    "B = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9S8tqIMG25pb"
   },
   "source": [
    "### Part 2. Classification with logistic regression and kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2docs4225pb"
   },
   "source": [
    "Today we will work with [Forest data subset from UCI repository](http://archive.ics.uci.edu/ml/datasets/Covertype). The dataset has the following structure: 7 classes, 54 features (40 of which are binary). Description is available at the link above or in the file `covtype.info.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If on colab, uncomment the following lines\n",
    "\n",
    "# !wget https://github.com/girafe-ai/intro-to-ml-harbour/raw/master/assignments/assignment_2_lin_classsification/forest_dataset.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rvPrVRvK25pc"
   },
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('forest_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrX0W5si25pe"
   },
   "source": [
    "Let's take last 20% of the dataset into the `delayed_data` variable and use it in the end for final models evaluation (it will be the \"new\" dataset). The rest of the data should be stored in variable `all_data`. Let's not shuffle the datasets today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Deu3A-yc25pf"
   },
   "outputs": [],
   "source": [
    "delayed_data = all_data[int(0.8 * len(all_data)):]\n",
    "all_data = all_data[:int(0.8 * len(all_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itCWxHEY25pg"
   },
   "source": [
    "Let's place the target values (class labels) into the variable `labels`, the design matrix into the variable `feature_matrix`. The dataset we are working with is fully numeric and doesn't have any missing values, so we can work with `numpy`-formatted data. Let's get it using the `.values` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "f_YIUOuV25ph"
   },
   "outputs": [],
   "source": [
    "labels = all_data[all_data.columns[-1]].values\n",
    "feature_matrix = all_data[all_data.columns[:-1]].values\n",
    "\n",
    "delayed_labels = delayed_data[delayed_data.columns[-1]].values\n",
    "delayed_feature_matrix = delayed_data[delayed_data.columns[:-1]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dKCiU0wz25pj"
   },
   "source": [
    "#### 2.1 Binary classification (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYDttiOJ25pj"
   },
   "source": [
    "We start with the binary classification problem. Train a linear classifier (`LogisticRegression`) to separate two classes. Split the available data (`all_data`) into train and test parts using `train_test_split` with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q030jzyY25pl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "taWX6ME925pn"
   },
   "outputs": [],
   "source": [
    "two_class_labels_indices = (labels == 1) + (labels == 2)\n",
    "\n",
    "two_class_feature_matrix = feature_matrix[two_class_labels_indices]\n",
    "two_class_labels = labels[two_class_labels_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zoQPXD_k25po"
   },
   "outputs": [],
   "source": [
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = <your_code_here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8iDa9Je25pq"
   },
   "source": [
    "Train the classifier. Estimate the quality of the trained model on the test set (`test_feature_matrix`) using `accuracy` score and `f1_score`([Wikipedia](https://en.wikipedia.org/wiki/F1_score))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9CKtjwv_25pr"
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VF2CeR7W25pt"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the ROC curve and compute the ROC-AUC for this binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9MKHZ2JC25pv"
   },
   "source": [
    "#### 2.2 Multi-class Classification: Logistic Regression (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1mWe4kJ25pv"
   },
   "source": [
    "**Note:**\n",
    "\n",
    "*Logistic regression may be used to solve N-class classification tasks. ``LogisticRegression`` class allows to do it in two ways:* \n",
    "- *1. Standard One vs. Rest (each class is separated from other N-1 classes). Set ``LogisticRegression`` class parameter `multi_class='ovr'`.*\n",
    "- *2. Using cross-entropy function (model output is a vector of probability estimates for each class). ``LogisticRegression`` class parameter `multi_class='multinomial'`.*\n",
    "\n",
    "*Let's use second option as default.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGn7U05I25pw"
   },
   "source": [
    "Let's now use all the 7 available covertypes. Necessary data is stored in variables `feature_matrix` и `labels` if you didn't overwrite them. Split your dataset into training and testing parts using `train_test_split` function using the following parameters: `test_size=0.2`, `random_state=42`. Fit logistic regression to the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xqzEKcdD25px"
   },
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QqTntPq25p0"
   },
   "source": [
    "Using 5-fold cross-validation (`GridSearchCV`) select optimal values for `C` and `penalty`. A range of values `np.logspace(-5, 5, 11)` should be used for `C` and a list of two options `['l1', 'l2']` - for `penalty`. Use accuracy to estimate the cross-validaiton performance: `scoring = 'accuracy'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "j-M-porJ25p0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzsRzpiv25p2"
   },
   "source": [
    "Plot average `accuracy` values for different types of regularization `l1` and `l2` depending on regularization coefficient `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nYOrtHpy25p3"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQraNf0M25p5"
   },
   "source": [
    "Analyze the resulting plots. What values of `C` and `penalty` provide the best model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "BkT1RWJj25p7"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIX7uVYk25p9"
   },
   "source": [
    "Using the optimal values for `C` and `penalty`, fit logistic regression to the training set and compute the class probabilities for the testing set (`best_lr_clf.predict_proba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "1rDNazlC25p9"
   },
   "outputs": [],
   "source": [
    "best_lr_clf = LogisticRegression(<your_best_params_here>)\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ck7T2dGQ25p_"
   },
   "source": [
    "Compute the average class probability values for testing set, using the results of the previous cell. Compare the resulting probability distribution to the class probability estimation, based of label frequency in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JOf0BNix25qA"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might use the ROC AUC for the multiclass as well (we recommend library `scikitplot`). Then the process will be that easy:\n",
    "```\n",
    "scikitplot.metrics.plot_roc(y_true, predicted_proba)\n",
    "```\n",
    "\n",
    "It's not mandatory, but we highly recommend to build the ROC curve for the multiclass classification as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYogShkD25qD"
   },
   "source": [
    "#### 2.3 Multi-class Classification: kNN (2 points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BHVNCaJ325qD"
   },
   "source": [
    "Fit `KNeighborsClassifier` implemented in `sklearn` to the training set mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "o4CMnnOY25qD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl_foM3u25qF"
   },
   "source": [
    "Try using different weight functions, used in predictions: `[‘uniform’, ‘distance’]`. Select the one that you consider reasonable and explain your choice.\n",
    "\n",
    "Use a grid from `1` to `10` for the `n_neighbors` parameter. Plot the resulting KNN classifier `accuracy` depending on the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4lMSy-6f25qG"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBmiDbvV25qI"
   },
   "source": [
    "Using the optimal number of neighbors, compute class probabilities for the testing set (`.predict_proba`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ig_vS8O925qI"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `best_knn_clf`object, which represents the optimal classifier in terms of cross-validation `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: pass the weight function type and number of neighbors to the class constructor\n",
    "\n",
    "best_knn_clf = KNeighborsClassifier(n_neighbors=<number of neighbors>, weights=<'uniform' or 'distance'>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p41xvYTU25qK"
   },
   "source": [
    "#### 2.4 Compare Logistic Regression and kNN (1 point).\n",
    "\n",
    "In real life new data becomes available and updates your dataset as the time comes. Compare the performance of your best logistic regression model `best_lr_clf` and the best kNN `best_knn_clf` using the delayed subset `delayed_data`. Which model shows the best performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xJFKTJx425qL"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dKCiU0wz25pj",
    "9MKHZ2JC25pv",
    "VYogShkD25qD",
    "p41xvYTU25qK"
   ],
   "default_view": {},
   "name": "HW1_Logistic_regression_and_SVM.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
